---
title: "BayesIngenuo"
author: "Cristopher Barrios, Carlos Daniel Estrada"
date: "2023-03-17"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
librerias
```{r  warning=FALSE, unload=TRUE}
library(rpart)
library(rpart.plot)
library(dplyr) 
library(fpc) 
library(cluster) 
library("ggpubr") 
library(mclust)
library(caret)
library(tree)
library(randomForest)
library(plyr)
library("stats")
library("datasets")
library("prediction")
library(tidyverse)
library(e1071)
library(caret)
library(mlbench)
library(e1071)
```

### 1. Use los mismos conjuntos de entrenamiento y prueba que utilizó en las dos hojas anteriores.
```{r}
datos = read.csv("./train.csv")

test<- read.csv("./test.csv", stringsAsFactors = FALSE)
```

```{r}

set_entrenamiento <- sample_frac(datos, .7)
set_prueba <-setdiff(datos, set_entrenamiento)


drop <- c("LotFrontage", "Alley", "MasVnrType", "MasVnrArea", "BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2", "Electrical", "FireplaceQu", "GarageType", "GarageYrBlt", "GarageFinish", "GarageQual", "GarageCond", "PoolQC", "Fence", "MiscFeature")
set_entrenamiento <- set_entrenamiento[, !(names(set_entrenamiento) %in% drop)]
set_prueba <- set_prueba[, !(names(set_prueba) %in% drop)]
```
### 2. Elabore un modelo de regresión usando bayes ingenuo (naive bayes), el conjunto de entrenamiento y la variable respuesta SalesPrice. Prediga con el modelo y explique los resultados a los que llega. Asegúrese que los conjuntos de entrenamiento y prueba sean los mismos de las hojas anteriores para que los modelos sean comparables.
```{r }
#percentiles
percentil <- quantile(datos$SalePrice)


estado<-c('Estado')
datos$Estado<-estado
datos <- within(datos, Estado[SalePrice<=129975] <- 'Economica')
datos$Estado[(datos$SalePrice>129975 &datos$SalePrice<=163000)] <- 'Intermedia'
datos$Estado[datos$SalePrice>163000] <- 'Cara'


#Bayes 
porcentaje<-0.7

set.seed(1234)
corte <- sample(nrow(datos),nrow(datos)*porcentaje)

#Entrenamiento
train<-datos[corte,]
#Prueba
test<-datos[-corte,]

corte

```

Se ultilizo el mismo set de prueba anteriorior 

### 3. Haga un modelo de clasificación, use la variable categórica que hizo con el precio de las casas (barata, media y cara) como variable respuesta.
```{r  warning=FALSE, unload=TRUE}
#modelo
modelo<-naiveBayes(train$Estado~., data=train)

#Casting 
test$GrLivArea<-as.numeric(test$GrLivArea)
test$YearBuilt<-as.numeric(test$YearBuilt)
test$BsmtUnfSF<-as.numeric(test$BsmtUnfSF)
test$TotalBsmtSF<-as.numeric(test$TotalBsmtSF)
test$GarageArea<-as.numeric(test$GarageArea)
test$YearRemodAdd<-as.numeric(test$YearRemodAdd)
test$SalePrice<-as.numeric(test$SalePrice)
test$LotArea<-as.numeric(test$LotArea)

#prediccion
predBayes<-predict(modelo, newdata = test[,c("GrLivArea","YearBuilt","BsmtUnfSF","TotalBsmtSF","GarageArea","YearRemodAdd", "SalePrice","LotArea")])

#Convertimos
predBayes<-as.factor(predBayes)

predBayes

```
El modelo clasifica las casas en economica, intermedia en cara según el parametro utilizado en la hoja anterior, < 170,000 dólares es económica, entre 171,000 y 289,000 dólares es de un valor intermedio, y > 290,000 dolares es una casa cara. 

### 4. Utilice los modelos con el conjunto de prueba y determine la eficiencia del algoritmo para predecir y clasificar.
```{r}
prediction <- predict(modelo, test)
prediction

```

En cuanto a la eficiencia del algoritmo, se realizó la predicción del conjunto de prueba con el modelo de clasificación y se comparó con la clasificación real del conjunto de prueba. 

### 5. Analice los resultados del modelo de regresión. ¿Qué tan bien le fue prediciendo?
```{r}
mse <- mean((prediction - test
             $SalePrice)**2)
mse

```
Se puede observar que el modelo pudo predecir la mayor parte de los datos de prueba, por lo que se puede decir que está bien implementado.  

### 6. Compare los resultados con el modelo de regresión lineal y el árbol de regresión que hizo en las hojas pasadas. ¿Cuál funcionó mejor?

```{r}
porciento <- 70/100
datos$clasificacion <- ifelse(datos$SalePrice <= 251000, "Economicas", ifelse(datos$SalePrice <= 538000, "Intermedias", ifelse(datos$SalePrice <= 755000, "Caras")))

datos$y <- as.numeric(factor(datos$clasificacion))
datosCC <- datos[,c(2,4,18,19,20,21,27,35,37,38,39,44,45,46,47,48,49,50,51,52,53,55,57,60,62,63,67,68,69,70,71,72,76,77,78,81,83)]
datosCC <- datosCC[,colSums(is.na(datosCC))==0]
set.seed(123)
trainRowsNumber<-sample(nrow(datosCC),porciento*nrow(datosCC))
train<-datosCC[trainRowsNumber,]
test<-datosCC[-trainRowsNumber,]

fitLM<-lm(SalePrice~., data = train) 
summary(fitLM)

```

```{r}
arbol_3 <- rpart(SalePrice ~ ., data = set_entrenamiento)

prp(arbol_3, main="Arbol de Regresion", nn=TRUE, fallen.leaves = TRUE, shadow.col = "green", branch.lty = 3, branch = .5, faclen = 0, trace = 1, split.cex = 0.8, split.box.col = "lightblue", split.border.col = "blue", split.round = 0.5)
```
Tanto el árbol de decision como los valles ingenuos realizaron un mejor trabajo predijendo que el modelo de regresión lineal. A pedsar de que la difrencia no sea muyb notoria, el arbol de decisiones lo hizo mejor que  el modelo con bayes ingenuos. 

### 7. Haga un análisis de la eficiencia del modelo de clasificación usando una matriz de confusión. Tenga en cuenta la efectividad, donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores.
```{r}

#confusion
#cm<-caret::confusionMatrix(as.factor(predBayes),as.factor(test$Estado))
#cm


#########(A Carlos Daniel le corre en .tex)
```
La matriz de confusión muestra la precisión del modelo en la clasificación de las casas en las tres categorías económica, intermedia y cara. Los resultados muestran que el modelo clasifica correctamente la mayoría de las casas. 

Es importante tener en cuenta que los errores de clasificación pueden tener diferentes impactos según la categoría. Por ejemplo, clasificar una casa como económica cuando en realidad es cara puede ser más grave que clasificar una casa como intermedia cuando en realidad es económica. Por lo tanto, es importante tener en cuenta no solo la tasa de precisión del modelo, sino también los tipos de errores de clasificación y su impacto en la toma de decisiones basada en la clasificación del modelo.

### 8. Analice el modelo. ¿Cree que pueda estar sobre ajustado?

Si un modelo presenta un alto nivel de precisión y porcentajes de comportamiento similares, es posible suponer que haya ocurrido un sobreajuste. Sin embargo, para confirmarlo, es necesario compararlo con otro conjunto de datos mediante la validación cruzada. De esta forma, podremos determinar si realmente ha habido sobreajuste o no.

### 9. Haga un modelo usando validación cruzada, compare los resultados de este con los del modelo anterior. ¿Cuál funcionó mejor?

```{r}

#Convertir a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)

#conjunto entrenamiento y prueba
set.seed(123)
EIndex <- createDataPartition(datos$SalePrice, p = 0.7, list = FALSE)
datosEntrenamiento <- set_entrenamiento[EIndex, ]
datosTest <- set_entrenamiento[-EIndex, ]

#Entrenar modelo
nb_model <- naiveBayes(SalePrice ~ ., data = datosEntrenamiento)

#predicciones
predictions <- predict(nb_model, datosTest)
head(predictions, 5)

#Matriz de confusión
confusionMatrix(predictions, datosTest$SalePrice)$table[1:5, ]
```
Con el método de Bayes, experimentamos una mejora algo limitada pero en líneas generales fue positiva. Experimentamos un incremento en el número de viviendas clasificadas como caras, intermedias y económicas.

### 10. Compare la eficiencia del algoritmo con el resultado obtenido con el árbol de decisión (el de clasificación) y el modelo de random forest que hizo en la hoja pasada. ¿Cuál es mejor para predecir? ¿Cuál se demoró más en procesar?

Se puede decir que el árbol de decisión predijo mejor los precios que el modelo de naive bayes, ya que generó datos más exactos y es más fácil de comprender, sin embargo el modelo es un poco mas rápido en la ejecución. 
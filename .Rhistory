train<-datos[corte,]
#Prueba
test<-datos[-corte,]
Estado
#percentiles
percentil <- quantile(datos$SalePrice)
estado<-c('Estado')
datos$Estado<-estado
datos <- within(datos, Estado[SalePrice<=129975] <- 'Economica')
datos$Estado[(datos$SalePrice>129975 &datos$SalePrice<=163000)] <- 'Intermedia'
datos$Estado[datos$SalePrice>163000] <- 'Cara'
#Bayes
porcentaje<-0.7
set.seed(1234)
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
#Entrenamiento
train<-datos[corte,]
#Prueba
test<-datos[-corte,]
estado
#percentiles
percentil <- quantile(datos$SalePrice)
estado<-c('Estado')
datos$Estado<-estado
datos <- within(datos, Estado[SalePrice<=129975] <- 'Economica')
datos$Estado[(datos$SalePrice>129975 &datos$SalePrice<=163000)] <- 'Intermedia'
datos$Estado[datos$SalePrice>163000] <- 'Cara'
#Bayes
porcentaje<-0.7
set.seed(1234)
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
#Entrenamiento
train<-datos[corte,]
#Prueba
test<-datos[-corte,]
percentil
set_entrenamiento <- sample_frac(datos, .7)
set_prueba <-setdiff(datos, set_entrenamiento)
drop <- c("LotFrontage", "Alley", "MasVnrType", "MasVnrArea", "BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2", "Electrical", "FireplaceQu", "GarageType", "GarageYrBlt", "GarageFinish", "GarageQual", "GarageCond", "PoolQC", "Fence", "MiscFeature")
set_entrenamiento <- set_entrenamiento[, !(names(set_entrenamiento) %in% drop)]
set_prueba <- set_prueba[, !(names(set_prueba) %in% drop)]
#percentiles
percentil <- quantile(datos$SalePrice)
estado<-c('Estado')
datos$Estado<-estado
datos <- within(datos, Estado[SalePrice<=129975] <- 'Economica')
datos$Estado[(datos$SalePrice>129975 &datos$SalePrice<=163000)] <- 'Intermedia'
datos$Estado[datos$SalePrice>163000] <- 'Cara'
#Bayes
porcentaje<-0.7
set.seed(1234)
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
#Entrenamiento
train<-datos[corte,]
#Prueba
test<-datos[-corte,]
corte
#modelo
modelo<-naiveBayes(train$Estado~., data=train)
#Casting
test$GrLivArea<-as.numeric(test$GrLivArea)
test$YearBuilt<-as.numeric(test$YearBuilt)
test$BsmtUnfSF<-as.numeric(test$BsmtUnfSF)
test$TotalBsmtSF<-as.numeric(test$TotalBsmtSF)
test$GarageArea<-as.numeric(test$GarageArea)
test$YearRemodAdd<-as.numeric(test$YearRemodAdd)
test$SalePrice<-as.numeric(test$SalePrice)
test$LotArea<-as.numeric(test$LotArea)
#prediccion
predBayes<-predict(modelo, newdata = test[,c("GrLivArea","YearBuilt","BsmtUnfSF","TotalBsmtSF","GarageArea","YearRemodAdd", "SalePrice","LotArea")])
#Convertimos
predBayes<-as.factor(predBayes)
#modelo
modelo<-naiveBayes(train$Estado~., data=train)
#Casting
test$GrLivArea<-as.numeric(test$GrLivArea)
test$YearBuilt<-as.numeric(test$YearBuilt)
test$BsmtUnfSF<-as.numeric(test$BsmtUnfSF)
test$TotalBsmtSF<-as.numeric(test$TotalBsmtSF)
test$GarageArea<-as.numeric(test$GarageArea)
test$YearRemodAdd<-as.numeric(test$YearRemodAdd)
test$SalePrice<-as.numeric(test$SalePrice)
test$LotArea<-as.numeric(test$LotArea)
#prediccion
predBayes<-predict(modelo, newdata = test[,c("GrLivArea","YearBuilt","BsmtUnfSF","TotalBsmtSF","GarageArea","YearRemodAdd", "SalePrice","LotArea")])
#Convertimos
predBayes<-as.factor(predBayes)
#modelo
modelo<-naiveBayes(train$Estado~., data=train)
#Casting
test$GrLivArea<-as.numeric(test$GrLivArea)
test$YearBuilt<-as.numeric(test$YearBuilt)
test$BsmtUnfSF<-as.numeric(test$BsmtUnfSF)
test$TotalBsmtSF<-as.numeric(test$TotalBsmtSF)
test$GarageArea<-as.numeric(test$GarageArea)
test$YearRemodAdd<-as.numeric(test$YearRemodAdd)
test$SalePrice<-as.numeric(test$SalePrice)
test$LotArea<-as.numeric(test$LotArea)
#prediccion
predBayes<-predict(modelo, newdata = test[,c("GrLivArea","YearBuilt","BsmtUnfSF","TotalBsmtSF","GarageArea","YearRemodAdd", "SalePrice","LotArea")])
#Convertimos
predBayes<-as.factor(predBayes)
predBayes
library(caret)
library(mlbench)
folds <- createFolds(set_entrenamiento$SalePrice, k = 10)
data("PimaIndiansDiabetes")
library(caret)
library(mlbench)
folds <- createFolds(set_entrenamiento$SalePrice, k = 10)
data("PimaIndiansDiabetes")
setwd("C:/Users/estra/OneDrive/Documentos/GitHub/HojaT5-BayesIngenuo-MineriaDeDatos")
library(caret)
library(mlbench)
folds <- createFolds(set_entrenamiento$SalePrice, k = 10)
data("PimaIndiansDiabetes")
library(caret)
library(mlbench)
folds <- createFolds(set_entrenamiento$SalePrice, k = 10)
data("PimaIndiansDiabetes")
E_index <- createDataPartition(PimaIndiansDiabetes$diabetes, p = 0.7, list = FALSE) #70
#entrenar con 30 pruebas
entrenamiento <- PimaIndiansDiabetes[entrenamiento_index, ]
library(caret)
library(mlbench)
folds <- createFolds(set_entrenamiento$SalePrice, k = 10)
data("PimaIndiansDiabetes")
E_index <- createDataPartition(PimaIndiansDiabetes$diabetes, p = 0.7, list = FALSE) #70
#entrenar con 30 pruebas
entrenamiento <- PimaIndiansDiabetes[E_index, ]
pruebas <- PimaIndiansDiabetes[-E_index, ]
library(caret)
library(mlbench)
folds <- createFolds(set_entrenamiento$SalePrice, k = 10)
data("PimaIndiansDiabetes")
E_index <- createDataPartition(PimaIndiansDiabetes$diabetes, p = 0.7, list = FALSE) #70
#entrenar con 30 pruebas
entrenamiento <- PimaIndiansDiabetes[E_index, ]
pruebas <- PimaIndiansDiabetes[-E_index, ]
f <- diabetes ~ .
library(caret)
library(mlbench)
folds <- createFolds(set_entrenamiento$SalePrice, k = 10)
data("PimaIndiansDiabetes")
E_index <- createDataPartition(PimaIndiansDiabetes$diabetes, p = 0.7, list = FALSE) #70
#entrenar con 30 pruebas
entrenamiento <- PimaIndiansDiabetes[E_index, ]
pruebas <- PimaIndiansDiabetes[-E_index, ]
f <- diabetes ~ .
#entrenar modelo
m1 <- train(f, data = entrenamiento, method = "glm", trControl = trainControl(method = "cv", number = 10))
#predicciones
pred <- predict(m1, newdata = pruebas)
#rendimiento
rendimiento <- mean(pred == pruebas$diabetes)
cat(rendimiento)
library(caret)
library(mlbench)
folds <- createFolds(set_entrenamiento$SalePrice, k = 10)
data("PimaIndiansDiabetes")
E_index <- createDataPartition(PimaIndiansDiabetes$diabetes, p = 0.7, list = FALSE) #70
#entrenar con 30 pruebas
entrenamiento <- PimaIndiansDiabetes[E_index, ]
pruebas <- PimaIndiansDiabetes[-E_index, ]
f <- diabetes ~ .
#entrenar modelo
m1 <- train(f, data = entrenamiento, method = "glm", trControl = trainControl(method = "cv", number = 10))
#predicciones
pred <- predict(m1, newdata = pruebas)
#rendimiento
rendimiento <- mean(pred == pruebas$diabetes)
cat(rendimiento)
#entrenar modelo
m2 <- train(f, data = entrenamiento, method = "glm", trControl = trainControl(method = "cv", number = 10))
#predicciones
pred <- predict(m1, newdata = pruebas)
#rendimiento
rendimiento <- mean(pred == pruebas$diabetes)
cat(rendimiento)
library(caret)
library(mlbench)
folds <- createFolds(set_entrenamiento$SalePrice, k = 10)
data("PimaIndiansDiabetes")
E_index <- createDataPartition(PimaIndiansDiabetes$diabetes, p = 0.7, list = FALSE) #70
#entrenar con 30 pruebas
entrenamiento <- PimaIndiansDiabetes[E_index, ]
pruebas <- PimaIndiansDiabetes[-E_index, ]
f <- diabetes ~ .
#entrenar modelo
m1 <- train(f, data = entrenamiento, method = "glm", trControl = trainControl(method = "cv", number = 10))
#predicciones
pred <- predict(m1, newdata = pruebas)
#rendimiento
rendimiento <- mean(pred == pruebas$diabetes)
cat(rendimiento)
#entrenar modelo
m2 <- train(f, data = entrenamiento, method = "glm", trControl = trainControl(method = "cv", number = 10))
#predicciones
pred <- predict(m1, newdata = pruebas)
#rendimiento
rendimiento2 <- mean(pred == pruebas$diabetes)
cat(rendimiento2)
library(caret)
library(mlbench)
folds <- createFolds(set_entrenamiento$SalePrice, k = 10)
data("PimaIndiansDiabetes")
E_index <- createDataPartition(PimaIndiansDiabetes$diabetes, p = 0.7, list = FALSE) #70
#entrenar con 30 pruebas
entrenamiento <- PimaIndiansDiabetes[E_index, ]
pruebas <- PimaIndiansDiabetes[-E_index, ]
f <- diabetes ~ .
#entrenar modelo
m1 <- train(f, data = entrenamiento, method = "glm", trControl = trainControl(method = "cv", number = 10))
#predicciones
pred <- predict(m1, newdata = pruebas)
#rendimiento
rendimiento <- mean(pred == pruebas$diabetes)
cat(rendimiento)
#entrenar modelo
m2 <- train(f, data = entrenamiento, method = "glm", trControl = trainControl(method = "cv", number = 10))
#predicciones
pred <- predict(m2, newdata = pruebas)
#rendimiento
rendimiento2 <- mean(pred == pruebas$diabetes)
cat(rendimiento2)
library(rpart)
library(rpart.plot)
library(dplyr)
library(fpc)
library(cluster)
library("ggpubr")
library(mclust)
library(caret)
library(tree)
library(randomForest)
library(plyr)
library("stats")
library("datasets")
library("prediction")
library(tidyverse)
library(e1071)
library(caret)
library(mlbench)
library(rpart)
library(rpart.plot)
library(dplyr)
library(fpc)
library(cluster)
library("ggpubr")
library(mclust)
library(caret)
library(tree)
library(randomForest)
library(plyr)
library("stats")
library("datasets")
library("prediction")
library(tidyverse)
library(e1071)
library(caret)
library(mlbench)
library(rpart)
library(rpart.plot)
library(dplyr)
library(fpc)
library(cluster)
library("ggpubr")
library(mclust)
library(caret)
library(tree)
library(randomForest)
library(plyr)
library("stats")
library("datasets")
library("prediction")
library(tidyverse)
library(e1071)
library(caret)
library(mlbench)
# Convertir variable respuesta a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)
# Dividir en conjunto de entrenamiento y prueba
set.seed(123)
train_index <- sample(nrow(train_data), round(0.7 * nrow(set_entrenamiento)))
# Convertir variable respuesta a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)
# Dividir en conjunto de entrenamiento y prueba
set.seed(123)
train_index <- sample(nrow(train_data), round(0.7 * nrow(set_entrenamiento)))
# Convertir variable respuesta a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)
# Dividir en conjunto de entrenamiento y prueba
set.seed(123)
E_index <- sample(nrow(train_data), round(0.7 * nrow(set_entrenamiento)))
train_index <- createDataPartition(data$SalePrice, p = 0.7, list = FALSE)
# Convertir variable respuesta a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)
# Dividir en conjunto de entrenamiento y prueba
set.seed(123)
train_index <- createDataPartition(data$SalePrice, p = 0.7, list = FALSE)
# Convertir variable respuesta a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)
# Dividir en conjunto de entrenamiento y prueba
set.seed(123)
train_index <- createDataPartition(data$SalePrice, p = 0.7, list = FALSE)
# Convertir variable respuesta a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)
# Dividir en conjunto de entrenamiento y prueba
set.seed(123)
trainIndex <- createDataPartition(data$PriceCategory, p = 0.7, list = FALSE)
library(e1071)
library(caret)
# Convertir variable respuesta a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)
# Dividir en conjunto de entrenamiento y prueba
set.seed(123)
trainIndex <- createDataPartition(data$PriceCategory, p = 0.7, list = FALSE)
library(e1071)
library(caret)
# Convertir variable respuesta a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)
# Dividir en conjunto de entrenamiento y prueba
set.seed(123)
trainIndex <- createDataPartition(datos$PriceCategory, p = 0.7, list = FALSE)
library(e1071)
library(caret)
# Convertir variable respuesta a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)
# Dividir en conjunto de entrenamiento y prueba
set.seed(123)
#trainIndex <- createDataPartition(datos$PriceCategory, p = 0.7, list = FALSE)
train_data_train <- set_entrenamiento[train_index, ]
library(e1071)
library(caret)
# Convertir variable respuesta a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)
# Dividir en conjunto de entrenamiento y prueba
set.seed(123)
trainIndex <- createDataPartition(datos$PriceCategory, p = 0.7, list = FALSE)
library(e1071)
library(caret)
# Convertir variable respuesta a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)
# Dividir en conjunto de entrenamiento y prueba
set.seed(123)
trainIndex <- createDataPartition(datos$SalePrice, p = 0.7, list = FALSE)
train_data_train <- set_entrenamiento[train_index, ]
library(e1071)
library(caret)
# Convertir variable respuesta a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)
# Dividir en conjunto de entrenamiento y prueba
set.seed(123)
train_index <- createDataPartition(datos$SalePrice, p = 0.7, list = FALSE)
train_data_train <- set_entrenamiento[train_index, ]
train_data_test <- set_entrenamiento[-train_index, ]
# Entrenar modelo Naive Bayes
library(e1071)
nb_model <- naiveBayes(SalePrice ~ ., data = train_data_train)
# Realizar predicciones sobre conjunto de prueba
predictions <- predict(nb_model, train_data_test)
head(predictions, 5)
# Calcular matriz de confusión
library(caret)
confusionMatrix(predictions, train_data_test$SalePrice)$table[1:5, ]
library(rpart)
library(rpart.plot)
library(dplyr)
library(fpc)
library(cluster)
library("ggpubr")
library(mclust)
library(caret)
library(tree)
library(randomForest)
library(plyr)
library("stats")
library("datasets")
library("prediction")
library(tidyverse)
library(e1071)
library(caret)
library(mlbench)
library(e1071)
# Convertir variable respuesta a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)
# Dividir en conjunto de entrenamiento y prueba
set.seed(123)
E_index <- createDataPartition(datos$SalePrice, p = 0.7, list = FALSE)
train_data_train <- set_entrenamiento[train_index, ]
train_data_test <- set_entrenamiento[-train_index, ]
# Entrenar modelo Naive Bayes
nb_model <- naiveBayes(SalePrice ~ ., data = train_data_train)
# Realizar predicciones sobre conjunto de prueba
predictions <- predict(nb_model, train_data_test)
head(predictions, 5)
# Calcular matriz de confusión
confusionMatrix(predictions, train_data_test$SalePrice)$table[1:5, ]
# Convertir variable respuesta a factor
set_entrenamiento$SalePrice <- factor(set_entrenamiento$SalePrice)
# Dividir en conjunto de entrenamiento y prueba
set.seed(123)
E_index <- createDataPartition(datos$SalePrice, p = 0.7, list = FALSE)
train_data_train <- set_entrenamiento[E_index, ]
train_data_test <- set_entrenamiento[-E_index, ]
# Entrenar modelo Naive Bayes
nb_model <- naiveBayes(SalePrice ~ ., data = train_data_train)
# Realizar predicciones sobre conjunto de prueba
predictions <- predict(nb_model, train_data_test)
head(predictions, 5)
# Calcular matriz de confusión
confusionMatrix(predictions, train_data_test$SalePrice)$table[1:5, ]
folds <- createFolds(set_entrenamiento$SalePrice, k = 10)
data("PimaIndiansDiabetes")
E_index <- createDataPartition(PimaIndiansDiabetes$diabetes, p = 0.7, list = FALSE) #70
#entrenar con 30 pruebas
entrenamiento <- PimaIndiansDiabetes[E_index, ]
pruebas <- PimaIndiansDiabetes[-E_index, ]
f <- diabetes ~ .
#entrenar modelo
m1 <- train(f, data = entrenamiento, method = "glm", trControl = trainControl(method = "cv", number = 10))
#predicciones
pred <- predict(m1, newdata = pruebas)
#rendimiento
rendimiento <- mean(pred == pruebas$diabetes)
cat(rendimiento)
#entrenar modelo
m2 <- train(f, data = entrenamiento, method = "glm", trControl = trainControl(method = "cv", number = 10))
#predicciones
pred <- predict(m2, newdata = pruebas)
#rendimiento
rendimiento2 <- mean(pred == pruebas$diabetes)
cat(rendimiento2)
knitr::opts_chunk$set(echo = TRUE)
library(rpart)
library(rpart.plot)
library(dplyr)
library(fpc)
library(cluster)
library("ggpubr")
library(mclust)
library(caret)
library(tree)
library(randomForest)
library(plyr)
library("stats")
library("datasets")
library("prediction")
library(tidyverse)
library(e1071)
library(caret)
library(mlbench)
library(e1071)
datos = read.csv("./train.csv")
test<- read.csv("./test.csv", stringsAsFactors = FALSE)
set_entrenamiento <- sample_frac(datos, .7)
set_prueba <-setdiff(datos, set_entrenamiento)
drop <- c("LotFrontage", "Alley", "MasVnrType", "MasVnrArea", "BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2", "Electrical", "FireplaceQu", "GarageType", "GarageYrBlt", "GarageFinish", "GarageQual", "GarageCond", "PoolQC", "Fence", "MiscFeature")
set_entrenamiento <- set_entrenamiento[, !(names(set_entrenamiento) %in% drop)]
set_prueba <- set_prueba[, !(names(set_prueba) %in% drop)]
#percentiles
percentil <- quantile(datos$SalePrice)
estado<-c('Estado')
datos$Estado<-estado
datos <- within(datos, Estado[SalePrice<=129975] <- 'Economica')
datos$Estado[(datos$SalePrice>129975 &datos$SalePrice<=163000)] <- 'Intermedia'
datos$Estado[datos$SalePrice>163000] <- 'Cara'
#Bayes
porcentaje<-0.7
set.seed(1234)
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
#Entrenamiento
train<-datos[corte,]
#Prueba
test<-datos[-corte,]
corte
#modelo
modelo<-naiveBayes(train$Estado~., data=train)
#Casting
test$GrLivArea<-as.numeric(test$GrLivArea)
test$YearBuilt<-as.numeric(test$YearBuilt)
test$BsmtUnfSF<-as.numeric(test$BsmtUnfSF)
test$TotalBsmtSF<-as.numeric(test$TotalBsmtSF)
test$GarageArea<-as.numeric(test$GarageArea)
test$YearRemodAdd<-as.numeric(test$YearRemodAdd)
test$SalePrice<-as.numeric(test$SalePrice)
test$LotArea<-as.numeric(test$LotArea)
#prediccion
predBayes<-predict(modelo, newdata = test[,c("GrLivArea","YearBuilt","BsmtUnfSF","TotalBsmtSF","GarageArea","YearRemodAdd", "SalePrice","LotArea")])
#Convertimos
predBayes<-as.factor(predBayes)
predBayes
prediction <- predict(modelo, test)
prediction
mse <- mean((prediction - test
$SalePrice)**2)
mse
porciento <- 70/100
datos$clasificacion <- ifelse(datos$SalePrice <= 251000, "Economicas", ifelse(datos$SalePrice <= 538000, "Intermedias", ifelse(datos$SalePrice <= 755000, "Caras")))
datos$y <- as.numeric(factor(datos$clasificacion))
datosCC <- datos[,c(2,4,18,19,20,21,27,35,37,38,39,44,45,46,47,48,49,50,51,52,53,55,57,60,62,63,67,68,69,70,71,72,76,77,78,81,83)]
datosCC <- datosCC[,colSums(is.na(datosCC))==0]
set.seed(123)
trainRowsNumber<-sample(nrow(datosCC),porciento*nrow(datosCC))
train<-datosCC[trainRowsNumber,]
test<-datosCC[-trainRowsNumber,]
fitLM<-lm(SalePrice~., data = train)
summary(fitLM)
arbol_3 <- rpart(SalePrice ~ ., data = set_entrenamiento)
prp(arbol_3, main="Arbol de Regresion", nn=TRUE, fallen.leaves = TRUE, shadow.col = "green", branch.lty = 3, branch = .5, faclen = 0, trace = 1, split.cex = 0.8, split.box.col = "lightblue", split.border.col = "blue", split.round = 0.5)
#confusion
cm<-caret::confusionMatrix(as.factor(predBayes),as.factor(test$Estado))
